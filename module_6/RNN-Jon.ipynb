{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:brown;\">  Recurrent neural nets</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Looping network](./img/RNN_colah.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNNs can produce amazing results <a href =\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">blog</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson plan \n",
    "1. Why classic neural nets are not enough?\n",
    "2. Word embeddings - word2vec\n",
    "3. Categorical embeddings\n",
    "4. RNN \n",
    "5. Takeaways\n",
    "6. Hands on word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T17:33:58.224673Z",
     "start_time": "2019-07-15T17:33:58.217898Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic nets vs. RNN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic:\n",
    "    - Inputs and outputs must be fixed-sized vectors\n",
    "    - No idea of location or time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/diags.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Which word produces the highest probability to be next given we have seen n specific other words before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Words: Thank, you, Hello, goodbye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If we have 4 words and we are looking at 2-gram? \n",
    "    Example: no. of times Thank you occurs divided by number of times Thank occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate the probabilty of \n",
    " - Thank Hello\n",
    " - Thank you\n",
    " - Thank goodbye\n",
    " - Thank Thank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we needed to do 4 calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T17:44:06.745274Z",
     "start_time": "2019-07-15T17:44:06.738898Z"
    }
   },
   "outputs": [],
   "source": [
    "def how_many_calc_to_do(gram, voc_size):\n",
    "    '''This function needs to calculate all combos \n",
    "    of words'''\n",
    "    \n",
    "    return np.prod(np.repeat(voc_size, gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T17:44:07.369801Z",
     "start_time": "2019-07-15T17:44:07.355600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4477988020393345024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how_many_calc_to_do(7, 10000)\n",
    "# Notice that this is only an approxiamtion and it can be implemented in more efficient ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/one_hot_encoding_distance_on_3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight I: \n",
    "    we can actually just turn each word to a random vector sized 100/200/300, \n",
    "    train a classic neural net to predict the next word and update both the weights and the random vectors.\n",
    "    You can think of it as just another layer of weights multiplying the one hot encoded inputs.\n",
    "<a href=\"http://hunterheidenreich.com/blog/intro-to-word-embeddings/\">word_embed blog</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa\">word_embed blog II</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![W2V](./img/w2v.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective: maximize the sum of probabilities of each word given its observed window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea is very strong in comparison to other options: \n",
    "\n",
    "    Bag of words - just count occourences \n",
    "    TF-IDF - word is either informative or not but has no relation to other words\n",
    "    one-hot encoder: for the computer paris-france is the same distance as paris-blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distance and direction are meaningful! King - man = Queen - woman\n",
    "- Now the words massive and huge are similar!\n",
    "- Extends to sentences, paragraphs and documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/see_attached_word_embed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have reduced the dimension of the vocublary by a big factor!\n",
    "example: from 80,000 to 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.lemay.ai/demo/wordEmbedding/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insight I.I  The same thing can be applied to any categorical variable. \n",
    "##### With enough training data we can learn its continous position in space - state of the art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![categorical_embed](./img/categorical_embedding.png) # image I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![german_states](./img/german_states_mapped_2D.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight II: \n",
    "        well, even if we can include many words (large n-gram), how can we capture context?\n",
    "        If the text mentioned queen Mary and few pages later is talking about the queen, how will our network \n",
    "        know her name is Mary? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea I: Memory - your current choices are based on previous understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some cell in the network to keep previous memory and combine with current input to predict next word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/memory_rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: calculating the derivative (aka gradient) is problematic, either infinite or zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine the memory at time t is the memory at time t-1 times a weight vector:\n",
    "    $h_t = W*h_{t-1}$\n",
    "Then:\n",
    "    $h_t = W^t * h_0$ \n",
    "    \n",
    "  $W > 1$ $h_t --> \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: LSTM/GRU\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\">LSTM/GRU blog</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/RNNs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/LSTM_colah.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea II: gates: don't multiply, use addition for memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - cell state\n",
    "    - candidates  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gates\n",
    "- forget - information to throw (0 means throw all from the cell state)\n",
    "- input - what values we are going to update\n",
    "- output - filter which values of the cell we are going to output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current cell state is the sum of forgetting and updating with new candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension: attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.youtube.com/watch?v=SysgYptB198\">Intuition</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  - Translate part by part\n",
    "###### -  Use attention weights - how much attention should you give to each word in the input (update weights to each new word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word embeddings\n",
    "- Word/categorical embeddings gives meaning to words in relation to one another\n",
    "- Word/categorical embeddings are computationally efficient\n",
    "- Training is done through a classic NN with small window around words\n",
    "\n",
    "##### RNN\n",
    "- Old generation RNNs suffered from exploding/vanishing gradients\n",
    "- New generation RNNs (commonly LSTM or GRU) are using memory gates to mitigate this problem\n",
    "- RNNs are just multiple copies of a NN connected by the hidden layer\n",
    "- Training is done again by backpropogation\n",
    "- Weights are shared accros all network\n",
    "- RNN's can be used for any sequence. Unlike time series models can include both time and features.\n",
    "- Are flexible in input and output sizes\n",
    "- Amazing results in NLP, recommendations and many more.\n",
    "- Many flavours - BRNN, CRNN...\n",
    "\n",
    "##### Attention\n",
    "- Typicall for translations/images\n",
    "- Weight all the words in one language to decide how much they should influence input to translated language\n",
    "- components: word weights, BRNN, RNN, context vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands on Word2Vec/word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:37:54.634197Z",
     "start_time": "2019-07-15T18:37:49.405462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /anaconda3/envs/learn-env/lib/python3.6/site-packages (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (1.8.0)\n",
      "Collecting bz2file (from smart_open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: boto3 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (1.9.111)\n",
      "Requirement already satisfied: requests in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from smart_open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.111 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from boto3->smart_open>=1.2.1->gensim) (1.12.185)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from boto3->smart_open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from boto3->smart_open>=1.2.1->gensim) (0.2.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart_open>=1.2.1->gensim) (2.7)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.111->boto3->smart_open>=1.2.1->gensim) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.111->boto3->smart_open>=1.2.1->gensim) (2.8.0)\n",
      "Building wheels for collected packages: bz2file\n",
      "  Building wheel for bz2file (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jon/Library/Caches/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built bz2file\n",
      "Installing collected packages: bz2file\n",
      "Successfully installed bz2file-0.98\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:38:59.340173Z",
     "start_time": "2019-07-15T18:38:57.959940Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:39:09.927301Z",
     "start_time": "2019-07-15T18:39:09.205403Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('JEOPARDY_QUESTIONS1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:39:18.036003Z",
     "start_time": "2019-07-15T18:39:18.025745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:39:34.508472Z",
     "start_time": "2019-07-15T18:39:34.500703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'HISTORY',\n",
       " 'air_date': '2004-12-31',\n",
       " 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\",\n",
       " 'value': '$200',\n",
       " 'answer': 'Copernicus',\n",
       " 'round': 'Jeopardy!',\n",
       " 'show_number': '4680'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first element in our list\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:40:00.768973Z",
     "start_time": "2019-07-15T18:39:58.626475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec requires that our text have the form of a list\n",
    "# of 'sentences', where each sentence is itself a list of\n",
    "# words. How can we put our _Jeopardy!_ clues in that shape?\n",
    "\n",
    "text = []\n",
    "\n",
    "for clue in data:\n",
    "    sentence = clue['question'].translate(str.maketrans('', '',\n",
    "                                                        string.punctuation)).split(' ')\n",
    "    \n",
    "    new_sent = []\n",
    "    for word in sentence:\n",
    "        new_sent.append(word.lower())\n",
    "    \n",
    "    text.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:40:02.811070Z",
     "start_time": "2019-07-15T18:40:02.804098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life',\n",
       " 'galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " 'mans',\n",
       " 'theory']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the new structure of our first clue\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:41:41.473080Z",
     "start_time": "2019-07-15T18:41:13.593462Z"
    }
   },
   "outputs": [],
   "source": [
    "# simply a matter of\n",
    "# instantiating a Word2Vec object.\n",
    "model = gensim.models.Word2Vec(text, sg=1)\n",
    "## sg means skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:42:11.579058Z",
     "start_time": "2019-07-15T18:41:43.357345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11337324, 15849970)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train, call 'train()'!\n",
    "model.train(text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:42:13.371950Z",
     "start_time": "2019-07-15T18:42:13.367461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1a2b11b978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The '.wv' attribute stores the word vectors\n",
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:42:15.232662Z",
     "start_time": "2019-07-15T18:42:15.221334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.7743009e-01,  1.4484370e-01,  9.3734212e-02, -4.1861472e-01,\n",
       "       -6.7781366e-02,  2.9096228e-01,  2.0395963e-01,  4.4627026e-01,\n",
       "        3.5138341e-04,  5.0257817e-03, -8.8590890e-02,  2.3621009e-01,\n",
       "        4.9175479e-02,  3.7999126e-01,  9.2875212e-02, -1.5810581e-01,\n",
       "        5.6764424e-01, -3.2516658e-01,  4.4945118e-01, -3.9803747e-02,\n",
       "       -1.6991140e-02,  6.0898262e-01,  3.5365680e-01, -9.2984706e-01,\n",
       "       -2.2215913e-01,  4.9310226e-02,  4.8305467e-02,  2.2495875e-01,\n",
       "       -1.3135965e-01, -3.5769451e-01,  4.8653334e-01,  5.4739166e-02,\n",
       "        1.7923588e-01, -1.7729509e-01,  2.9537898e-01, -5.0075793e-01,\n",
       "       -2.4204971e-02, -6.4402051e-02, -3.1163868e-01,  1.4211130e-01,\n",
       "        1.1928944e-01,  3.3671731e-01, -2.1281394e-01,  2.1134712e-01,\n",
       "       -8.4556752e-01, -1.6900565e-01, -1.6961937e-01, -1.8624520e-01,\n",
       "        3.5867372e-01,  3.5848536e-02,  4.2364565e-01, -5.8288956e-01,\n",
       "        2.0673324e-01,  3.5535574e-01,  4.8856390e-01, -9.6862167e-03,\n",
       "        6.1709446e-01, -6.2873846e-01,  2.5608903e-02,  3.8086227e-01,\n",
       "       -7.4046001e-02, -4.6284493e-02,  3.3962464e-01, -2.2898376e-02,\n",
       "       -3.3221170e-01,  1.1492865e-02, -1.6124455e-03, -5.5334169e-01,\n",
       "        1.3321403e-01,  8.7779984e-02,  2.6964185e-01,  1.5027563e-01,\n",
       "       -1.7234161e-01,  4.8520941e-01, -3.3044347e-01, -1.2056223e-01,\n",
       "        4.1154228e-02,  1.3019715e-01, -5.5841964e-02,  2.4946363e-01,\n",
       "        3.7614444e-01,  2.6290950e-01, -3.1121477e-01, -6.0244882e-01,\n",
       "       -3.4184471e-01,  1.0340130e-01, -8.6473264e-02,  9.6610352e-02,\n",
       "       -5.2953404e-03, -2.5962976e-01,  1.4684311e-01, -2.5209785e-01,\n",
       "       -5.2587819e-01, -1.6278917e-01, -6.8377781e-01,  8.3621964e-02,\n",
       "       -6.3713962e-01, -4.4873051e-02, -3.4263289e-01, -4.0132162e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['child']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model.wv methods\n",
    "#### 'most_similar()' and 'similarity()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:44:01.073554Z",
     "start_time": "2019-07-15T18:44:00.843687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prosperity', 0.7474037408828735),\n",
       " ('ignorance', 0.744020938873291),\n",
       " ('autumns', 0.7291383743286133),\n",
       " ('anguish', 0.7205519676208496),\n",
       " ('compassion', 0.719251275062561),\n",
       " ('arise', 0.7164921760559082),\n",
       " ('shakespearebr', 0.7132083177566528),\n",
       " ('wherefore', 0.7123302221298218),\n",
       " ('goest', 0.7049089670181274),\n",
       " ('kindness', 0.7041229605674744)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:44:07.864419Z",
     "start_time": "2019-07-15T18:44:07.853839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artwork', 0.7191377878189087),\n",
       " ('pottery', 0.7097587585449219),\n",
       " ('ceramic', 0.7092421650886536),\n",
       " ('decorative', 0.70761638879776),\n",
       " ('chippendale', 0.6891075372695923),\n",
       " ('monogram', 0.6869503259658813),\n",
       " ('wearers', 0.6847445964813232),\n",
       " ('flooring', 0.6815633177757263),\n",
       " ('fasteners', 0.6767991185188293),\n",
       " ('wicker', 0.6764888763427734)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('furniture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:44:14.172702Z",
     "start_time": "2019-07-15T18:44:14.160272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6238540201781528"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('furniture', 'jewelry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:46:09.041684Z",
     "start_time": "2019-07-15T18:46:09.030894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reptile', 0.8152649402618408),\n",
       " ('shorthaired', 0.7939906120300293),\n",
       " ('carnivore', 0.7861495018005371),\n",
       " ('pachyderm', 0.7830628156661987),\n",
       " ('rodent', 0.7812258005142212),\n",
       " ('marsupial', 0.7785536646842957),\n",
       " ('parrot', 0.7755876779556274),\n",
       " ('giraffe', 0.7702314853668213),\n",
       " ('weasel', 0.7701903581619263),\n",
       " ('flightless', 0.769274115562439)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal', 'pet', 'mammal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:44:19.658509Z",
     "start_time": "2019-07-15T18:44:19.646650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('breed', 0.39183005690574646),\n",
       " ('insect', 0.3801022469997406),\n",
       " ('lizard', 0.3366336226463318),\n",
       " ('rodents', 0.3326495885848999),\n",
       " ('puppy', 0.3324885666370392),\n",
       " ('cows', 0.3302050828933716),\n",
       " ('dog', 0.32511675357818604),\n",
       " ('extinction', 0.3231205642223358),\n",
       " ('dogs', 0.32211077213287354),\n",
       " ('species', 0.318921834230423)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal'], negative='pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:47:37.905219Z",
     "start_time": "2019-07-15T18:47:37.893998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('throne', 0.25100433826446533),\n",
       " ('pharaoh', 0.24798095226287842),\n",
       " ('empress', 0.24761396646499634)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['king', 'woman'], negative='man', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:47:39.936952Z",
     "start_time": "2019-07-15T18:47:39.928908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pageant', 0.6598982810974121),\n",
       " ('fargo', 0.6350732445716858),\n",
       " ('tyra', 0.6186401844024658),\n",
       " ('xmas', 0.6108678579330444),\n",
       " ('npr', 0.6105656623840332),\n",
       " ('dogpatch', 0.6071796417236328),\n",
       " ('goings', 0.6024764776229858),\n",
       " ('guides', 0.6013813614845276),\n",
       " ('2000s', 0.5987871885299683),\n",
       " ('surfin', 0.5970957279205322)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:47:58.656080Z",
     "start_time": "2019-07-15T18:47:58.648160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('commonwealth', 0.7130832672119141),\n",
       " ('marianas', 0.6783615350723267),\n",
       " ('turkmenistan', 0.6684412956237793),\n",
       " ('timor', 0.6626874208450317),\n",
       " ('territories', 0.6608656644821167),\n",
       " ('britain', 0.6576970815658569),\n",
       " ('everglades', 0.6575170755386353),\n",
       " ('albania', 0.657362699508667),\n",
       " ('uruguay', 0.657297670841217),\n",
       " ('zambia', 0.6505134701728821)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:48:08.668064Z",
     "start_time": "2019-07-15T18:48:08.659969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sophocles', 0.7417839169502258),\n",
       " ('euripides', 0.7408822774887085),\n",
       " ('shakespeares', 0.7374973893165588),\n",
       " ('falstaff', 0.6937141418457031),\n",
       " ('moliere', 0.690405547618866),\n",
       " ('shakespearean', 0.6891647577285767),\n",
       " ('tragedy', 0.6753336191177368),\n",
       " ('rur', 0.6685926914215088),\n",
       " ('karel', 0.6617562770843506),\n",
       " ('ibsen', 0.6611332297325134)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:50:27.649381Z",
     "start_time": "2019-07-15T18:50:27.636978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('officially', 0.20530612766742706),\n",
       " ('dictator', 0.19773559272289276),\n",
       " ('yugoslavia', 0.195656880736351),\n",
       " ('emperors', 0.19515357911586761),\n",
       " ('czar', 0.1923864781856537),\n",
       " ('regime', 0.1913895159959793),\n",
       " ('shah', 0.183910071849823),\n",
       " ('khmer', 0.18301036953926086),\n",
       " ('empires', 0.1802889108657837),\n",
       " ('assassinated', 0.180212140083313)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'germany'], negative='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 'doesnt_match()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T18:48:43.358048Z",
     "start_time": "2019-07-15T18:48:43.350344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/models/keyedvectors.py:730: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['breakfast', 'lunch', 'frog', 'food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
