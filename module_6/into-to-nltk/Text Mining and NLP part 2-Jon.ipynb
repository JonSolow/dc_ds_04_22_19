{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and NLP\n",
    "\n",
    "## Part 2\n",
    "\n",
    "### Situation:\n",
    "\n",
    "Priya works at an international PR firm in the Europe division. Their largest client has offices in Ibiza, Madrid, and Las Palmas. She needs to keep her boss aware of current events and provide a weekly short list of articles concerning political events in Spain. The problem is, this takes hours every week to review articles on the BBC and Priya is very busy! She wonders if she could automate this process using text mining to save her time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal**: to internalize the steps, challenges, and methodology of text mining\n",
    "- explore text analysis by hand\n",
    "- apply text mining steps in Jupyter with Python libraries NLTK\n",
    "- classify documents correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresher on cleaning text\n",
    "![gif](https://www.nyfa.edu/student-resources/wp-content/uploads/2014/10/furious-crazed-typing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T17:57:24.958024Z",
     "start_time": "2019-07-09T17:57:24.902965Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "url_b = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/B.txt\"\n",
    "\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_a_st = article_a.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T17:57:25.512161Z",
     "start_time": "2019-07-09T17:57:25.481866Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokens\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "arta_tokens_raw = nltk.regexp_tokenize(article_a_st, pattern)\n",
    "\n",
    "# lower case\n",
    "arta_tokens = [i.lower() for i in arta_tokens_raw]\n",
    "\n",
    "# stop words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "arta_tokens_stopped = [w for w in arta_tokens if not w in stop_words]\n",
    "\n",
    "# stem words\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "arta_stemmed = [stemmer.stem(word) for word in arta_tokens_stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T17:57:25.972523Z",
     "start_time": "2019-07-09T17:57:25.920804Z"
    }
   },
   "outputs": [],
   "source": [
    "# repeat w second article\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's wrong with the table from yesterday? what does it not consider?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF score\n",
    "\n",
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The from scratch method\n",
    "![homemade](https://media2.giphy.com/media/LBZcXdG0eVBdK/giphy.gif?cid=3640f6095c2d7bb2526a424a4d97117c)\n",
    "\n",
    "\n",
    "Please go through the code and comment what each section does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T17:58:21.991313Z",
     "start_time": "2019-07-09T17:58:21.986263Z"
    }
   },
   "outputs": [],
   "source": [
    "# join the union of arta_stemmed and artb_stemmed\n",
    "wordSet = set(arta_stemmed).union(set(artb_stemmed))\n",
    "\n",
    "#Create 2 initial dictionaries with all zeroes as values and words as keys\n",
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:02:03.304508Z",
     "start_time": "2019-07-09T18:02:03.294405Z"
    }
   },
   "outputs": [],
   "source": [
    "# add to count in wordDictA for word in arta_stemmed\n",
    "for word in arta_stemmed:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "# add to count in wordDictA for word in artb_stemmed\n",
    "for word in artb_stemmed:\n",
    "    wordDictB[word]+=1    \n",
    "\n",
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    # iterate through each word and its count from provided wordDict\n",
    "    for word, count in wordDict.items():\n",
    "        # set stored dictionary word as key and count/totalwordcount as value\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict\n",
    "\n",
    "tfbowA = computeTF(wordDictA,arta_stemmed)\n",
    "tfbowB = computeTF(wordDictB,artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:12:36.738336Z",
     "start_time": "2019-07-09T18:12:36.718164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 0.010869565217391304,\n",
       " 'hurt': 0.010869565217391304,\n",
       " 'monetari': 0.0,\n",
       " 'support': 0.021739130434782608,\n",
       " 'dead': 0.0,\n",
       " 'member': 0.021739130434782608,\n",
       " 'busi': 0.010869565217391304,\n",
       " 'vocal': 0.010869565217391304,\n",
       " 'invent': 0.05434782608695652,\n",
       " 'fuller': 0.010869565217391304,\n",
       " 'believ': 0.0,\n",
       " 'reject': 0.010869565217391304,\n",
       " 'effect': 0.010869565217391304,\n",
       " 'begun': 0.0,\n",
       " 'read': 0.010869565217391304,\n",
       " 'fear': 0.010869565217391304,\n",
       " 'union': 0.010869565217391304,\n",
       " 'fail': 0.010869565217391304,\n",
       " 'financi': 0.010869565217391304,\n",
       " 'give': 0.010869565217391304,\n",
       " 'minist': 0.0,\n",
       " 'let': 0.010869565217391304,\n",
       " 'miss': 0.0,\n",
       " 'thought': 0.0,\n",
       " 'oppon': 0.010869565217391304,\n",
       " 'creditor': 0.0,\n",
       " 'suspend': 0.0,\n",
       " 'submit': 0.010869565217391304,\n",
       " 'shop': 0.010869565217391304,\n",
       " 'complet': 0.0,\n",
       " 'agre': 0.0,\n",
       " 'number': 0.0,\n",
       " 'hammer': 0.0,\n",
       " 'program': 0.010869565217391304,\n",
       " 'rewrit': 0.010869565217391304,\n",
       " 'propos': 0.021739130434782608,\n",
       " 'debt': 0.0,\n",
       " 'save': 0.0,\n",
       " 'fund': 0.0,\n",
       " 'play': 0.010869565217391304,\n",
       " 'concern': 0.010869565217391304,\n",
       " 'one': 0.03260869565217391,\n",
       " 'thursday': 0.0,\n",
       " 'financ': 0.0,\n",
       " 'word': 0.010869565217391304,\n",
       " 'announc': 0.0,\n",
       " 'idea': 0.0,\n",
       " 'germani': 0.0,\n",
       " 'hit': 0.0,\n",
       " 'base': 0.021739130434782608,\n",
       " 'state': 0.021739130434782608,\n",
       " 'reboot': 0.010869565217391304,\n",
       " 'favour': 0.010869565217391304,\n",
       " 'face': 0.0,\n",
       " 'juri': 0.021739130434782608,\n",
       " 'chancellor': 0.0,\n",
       " 'model': 0.010869565217391304,\n",
       " 'two': 0.021739130434782608,\n",
       " 'us': 0.03260869565217391,\n",
       " 'freez': 0.0,\n",
       " 'softwar': 0.03260869565217391,\n",
       " 'suffer': 0.010869565217391304,\n",
       " 'firm': 0.021739130434782608,\n",
       " 'controversi': 0.010869565217391304,\n",
       " 'impact': 0.010869565217391304,\n",
       " 'draft': 0.03260869565217391,\n",
       " 'pressur': 0.010869565217391304,\n",
       " 'current': 0.010869565217391304,\n",
       " 'month': 0.010869565217391304,\n",
       " 'say': 0.03260869565217391,\n",
       " 'start': 0.010869565217391304,\n",
       " 'tsunami': 0.0,\n",
       " 'small': 0.021739130434782608,\n",
       " 'gordon': 0.0,\n",
       " 'even': 0.010869565217391304,\n",
       " 'permit': 0.010869565217391304,\n",
       " 'reach': 0.0,\n",
       " 'jack': 0.0,\n",
       " 'expect': 0.0,\n",
       " 'offer': 0.010869565217391304,\n",
       " 'wealthi': 0.0,\n",
       " 'amazon': 0.010869565217391304,\n",
       " 'talk': 0.0,\n",
       " 'court': 0.010869565217391304,\n",
       " 'reconstruct': 0.0,\n",
       " 'g': 0.0,\n",
       " 'use': 0.010869565217391304,\n",
       " 'eu': 0.043478260869565216,\n",
       " 'lock': 0.0,\n",
       " 'first': 0.010869565217391304,\n",
       " 'larger': 0.010869565217391304,\n",
       " 'issu': 0.010869565217391304,\n",
       " 'also': 0.0,\n",
       " 'foreign': 0.0,\n",
       " 'debat': 0.010869565217391304,\n",
       " 'mep': 0.021739130434782608,\n",
       " 'countri': 0.0,\n",
       " 'without': 0.010869565217391304,\n",
       " 'implic': 0.010869565217391304,\n",
       " 'hold': 0.010869565217391304,\n",
       " 'lead': 0.010869565217391304,\n",
       " 'would': 0.03260869565217391,\n",
       " 'instruct': 0.0,\n",
       " 'develop': 0.010869565217391304,\n",
       " 'might': 0.010869565217391304,\n",
       " 'britain': 0.0,\n",
       " 'deal': 0.0,\n",
       " 'setback': 0.010869565217391304,\n",
       " 'secretari': 0.0,\n",
       " 'innov': 0.010869565217391304,\n",
       " 'happen': 0.010869565217391304,\n",
       " 'meet': 0.010869565217391304,\n",
       " 'world': 0.0,\n",
       " 'final': 0.0,\n",
       " 'commiss': 0.010869565217391304,\n",
       " 'problem': 0.0,\n",
       " 'later': 0.0,\n",
       " 'earlier': 0.0,\n",
       " 'servic': 0.010869565217391304,\n",
       " 'internet': 0.010869565217391304,\n",
       " 'week': 0.0,\n",
       " 'lobbi': 0.010869565217391304,\n",
       " 'friday': 0.0,\n",
       " 'protect': 0.021739130434782608,\n",
       " 'briton': 0.0,\n",
       " 'biggest': 0.0,\n",
       " 'larg': 0.010869565217391304,\n",
       " 'similar': 0.010869565217391304,\n",
       " 'momentum': 0.010869565217391304,\n",
       " 'decis': 0.010869565217391304,\n",
       " 'line': 0.010869565217391304,\n",
       " 'click': 0.010869565217391304,\n",
       " 'mean': 0.010869565217391304,\n",
       " 'agreement': 0.0,\n",
       " 'affect': 0.0,\n",
       " 'fight': 0.010869565217391304,\n",
       " 'group': 0.0,\n",
       " 'intens': 0.010869565217391304,\n",
       " 'com': 0.010869565217391304,\n",
       " 'interest': 0.0,\n",
       " 'european': 0.021739130434782608,\n",
       " 'direct': 0.043478260869565216,\n",
       " 'achiev': 0.010869565217391304,\n",
       " 'field': 0.010869565217391304,\n",
       " 'new': 0.021739130434782608,\n",
       " 'immens': 0.010869565217391304,\n",
       " 'chair': 0.0,\n",
       " 'moratorium': 0.0,\n",
       " 'committe': 0.021739130434782608,\n",
       " 'pound': 0.0,\n",
       " 'intern': 0.0,\n",
       " 'hope': 0.0,\n",
       " 'order': 0.021739130434782608,\n",
       " 'welcom': 0.010869565217391304,\n",
       " 'legal': 0.03260869565217391,\n",
       " 'law': 0.05434782608695652,\n",
       " 'vote': 0.010869565217391304,\n",
       " 'japan': 0.0,\n",
       " 'mr': 0.0,\n",
       " 'europ': 0.010869565217391304,\n",
       " 'nation': 0.010869565217391304,\n",
       " 'bn': 0.0,\n",
       " 'year': 0.0,\n",
       " 'could': 0.03260869565217391,\n",
       " 'parliament': 0.021739130434782608,\n",
       " 'intend': 0.010869565217391304,\n",
       " 'sign': 0.0,\n",
       " 'compani': 0.010869565217391304,\n",
       " 'patent': 0.05434782608695652,\n",
       " 'chanc': 0.010869565217391304,\n",
       " 'rule': 0.010869565217391304,\n",
       " 'govern': 0.010869565217391304,\n",
       " 'brown': 0.0,\n",
       " 'analysi': 0.0,\n",
       " 'critic': 0.021739130434782608,\n",
       " 'twice': 0.010869565217391304,\n",
       " 'serv': 0.010869565217391304,\n",
       " 'canada': 0.0,\n",
       " 'back': 0.021739130434782608,\n",
       " 'gain': 0.010869565217391304,\n",
       " 'said': 0.021739130434782608,\n",
       " 'disast': 0.0,\n",
       " 'repay': 0.0,\n",
       " 'bank': 0.0,\n",
       " 'put': 0.010869565217391304,\n",
       " 'straw': 0.0,\n",
       " 'comput': 0.043478260869565216,\n",
       " 'come': 0.0,\n",
       " 'implement': 0.021739130434782608,\n",
       " 'poland': 0.010869565217391304,\n",
       " 'ineffici': 0.010869565217391304,\n",
       " 'bring': 0.010869565217391304,\n",
       " 'largest': 0.010869565217391304,\n",
       " 'open': 0.010869565217391304,\n",
       " 'adopt': 0.010869565217391304,\n",
       " 'sourc': 0.010869565217391304,\n",
       " 'exampl': 0.010869565217391304,\n",
       " 'method': 0.010869565217391304,\n",
       " 'night': 0.0,\n",
       " 'abstain': 0.010869565217391304,\n",
       " 'affair': 0.010869565217391304}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:30:59.658679Z",
     "start_time": "2019-07-09T18:30:59.652361Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    # number of documents\n",
    "    N = len(docList)\n",
    "    # start empty dictionary to keep track of all counts\n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    \n",
    "    # for each document\n",
    "    for doc in docList:\n",
    "        # get count of documents where word count \n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    # for each word calculate count divided by total word count\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:30:59.850612Z",
     "start_time": "2019-07-09T18:30:59.842078Z"
    }
   },
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:31:00.080217Z",
     "start_time": "2019-07-09T18:31:00.072260Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:31:00.204002Z",
     "start_time": "2019-07-09T18:31:00.199729Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidfBowA = computeTFIDF(tfbowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfbowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:31:00.388356Z",
     "start_time": "2019-07-09T18:31:00.342277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>affect</th>\n",
       "      <th>agre</th>\n",
       "      <th>agreement</th>\n",
       "      <th>also</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>wealthi</th>\n",
       "      <th>week</th>\n",
       "      <th>welcom</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.01169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
       "0  0.003272  0.003272  0.003272  0.003272  0.003272  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.005845  0.005845   \n",
       "\n",
       "   agreement     also    amazon  ...     vocal      vote   wealthi      week  \\\n",
       "0   0.000000  0.00000  0.003272  ...  0.003272  0.003272  0.000000  0.000000   \n",
       "1   0.005845  0.01169  0.000000  ...  0.000000  0.000000  0.005845  0.005845   \n",
       "\n",
       "     welcom   without      word     world  would      year  \n",
       "0  0.003272  0.003272  0.003272  0.000000    0.0  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.005845    0.0  0.005845  \n",
       "\n",
       "[2 rows x 201 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfBowA, tfidfBowB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But yes, there is an easier way\n",
    "\n",
    "![big deal](https://media0.giphy.com/media/xUA7aQOxkz00lvCAOQ/giphy.gif?cid=3640f6095c2d7c51772f47644d09cc8b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:32:11.244019Z",
     "start_time": "2019-07-09T18:32:11.222629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
      "0  0.053285  0.053285  0.053285  0.053285  0.053285  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "   agreement      also    amazon  ...     vocal      vote   wealthi      week  \\\n",
      "0   0.000000  0.000000  0.053285  ...  0.053285  0.053285  0.000000  0.000000   \n",
      "1   0.084167  0.168334  0.000000  ...  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "     welcom   without      word     world     would      year  \n",
      "0  0.053285  0.053285  0.053285  0.000000  0.113738  0.000000  \n",
      "1  0.000000  0.000000  0.000000  0.084167  0.059885  0.084167  \n",
      "\n",
      "[2 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a string again\n",
    "cleaned_a = ' '.join(arta_stemmed)\n",
    "cleaned_b = ' '.join(artb_stemmed)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform([cleaned_a, cleaned_b])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics \n",
    "\n",
    "How many non-zero elements are there?\n",
    "- Adapt the code below, using the `df` version of the `response` object to replace everywhere below it says `DATA`\n",
    "- Interpret the findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:48:02.593109Z",
     "start_time": "2019-07-09T18:48:02.584451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 207\n",
      "Percentage of columns containing 0: 48.25%\n"
     ]
    }
   ],
   "source": [
    "# Edit code before running it\n",
    "\n",
    "non_zero_cols = np.sum(df.values>0)\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / np.ma.count(df.values))\n",
    "print('Percentage of columns containing 0: {:.2%}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:48:33.104808Z",
     "start_time": "2019-07-09T18:48:33.094447Z"
    }
   },
   "outputs": [],
   "source": [
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "\n",
    "letter_list = list(string.ascii_uppercase[0:12])\n",
    "url_list = [\"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/{}.txt\".format(ltr) for ltr in letter_list]\n",
    "\n",
    "def url_to_stemmed(url):\n",
    "    article_b = urllib.request.urlopen(url).read()\n",
    "    article_b_st = article_b.decode(\"utf-8\")\n",
    "    artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "    artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "    artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "    artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]\n",
    "    return ' '.join(artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:55:47.270600Z",
     "start_time": "2019-07-09T18:55:46.603377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reboot order eu patent law european parliament committe order rewrit propos controversi new european union rule govern comput base invent legal affair committe juri said commiss submit comput implement invent direct mep fail back vocal critic say could favour larg small firm impact open sourc softwar innov support say would let firm protect invent direct intend offer patent protect invent use softwar achiev effect word comput implement invent draft law suffer setback poland one largest eu member state reject adopt twice two month intens lobbi issu start gain momentum nation parliament put immens pressur two mep back draft law juri meet one vote abstain oppon draft direct welcom decis said new first read propos would give eu chanc fuller debat implic member state us patent comput program internet busi method permit mean us base amazon com hold patent one click shop servic exampl critic concern direct could lead similar model happen europ fear could hurt small softwar develop legal financi might larger compani fight patent legal action court support say current law ineffici would serv even play field without bring eu law line us'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_list = [url_to_stemmed(url) for url in url_list]\n",
    "stemmed_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:48:36.836963Z",
     "start_time": "2019-07-09T18:48:36.805493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        abat    abiyot       abl   abstain    access    accord   account  \\\n",
      "0   0.000000  0.000000  0.000000  0.057034  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.052499  0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.053013  0.053013  0.046830   \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.045945   \n",
      "8   0.000000  0.000000  0.093834  0.000000  0.080585  0.000000  0.035593   \n",
      "9   0.080947  0.080947  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       accur    achiev       acr  ...   wondimu      wood      word     world  \\\n",
      "0   0.000000  0.057034  0.000000  ...  0.000000  0.000000  0.057034  0.000000   \n",
      "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.050822   \n",
      "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.102819   \n",
      "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.251438   \n",
      "7   0.000000  0.000000  0.060563  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.052901   \n",
      "9   0.000000  0.000000  0.000000  ...  0.080947  0.000000  0.000000  0.273813   \n",
      "10  0.120328  0.000000  0.000000  ...  0.000000  0.060164  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.279027   \n",
      "\n",
      "       would      xbox      year      yepp        yh  yorkshir  \n",
      "0   0.096463  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1   0.050822  0.000000  0.036634  0.000000  0.000000  0.000000  \n",
      "2   0.068926  0.061129  0.099368  0.061129  0.061129  0.000000  \n",
      "3   0.000000  0.000000  0.047117  0.000000  0.000000  0.115942  \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5   0.102819  0.000000  0.074115  0.000000  0.000000  0.000000  \n",
      "6   0.000000  0.000000  0.025892  0.000000  0.000000  0.000000  \n",
      "7   0.000000  0.000000  0.024612  0.000000  0.000000  0.000000  \n",
      "8   0.026450  0.000000  0.019066  0.000000  0.000000  0.000000  \n",
      "9   0.000000  0.000000  0.065791  0.000000  0.000000  0.000000  \n",
      "10  0.101756  0.000000  0.024450  0.000000  0.000000  0.000000  \n",
      "11  0.000000  0.000000  0.057466  0.000000  0.000000  0.000000  \n",
      "\n",
      "[12 rows x 800 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform(stemmed_list)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:59:07.901908Z",
     "start_time": "2019-07-09T18:59:07.884509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reboot': 593,\n",
       " 'order': 521,\n",
       " 'eu': 225,\n",
       " 'patent': 534,\n",
       " 'law': 415,\n",
       " 'european': 227,\n",
       " 'parliament': 530,\n",
       " 'committe': 138,\n",
       " 'rewrit': 609,\n",
       " 'propos': 570,\n",
       " 'controversi': 159,\n",
       " 'new': 501,\n",
       " 'union': 750,\n",
       " 'rule': 615,\n",
       " 'govern': 304,\n",
       " 'comput': 149,\n",
       " 'base': 65,\n",
       " 'invent': 374,\n",
       " 'legal': 418,\n",
       " 'affair': 18,\n",
       " 'juri': 392,\n",
       " 'said': 618,\n",
       " 'commiss': 136,\n",
       " 'submit': 693,\n",
       " 'implement': 350,\n",
       " 'direct': 200,\n",
       " 'mep': 462,\n",
       " 'fail': 239,\n",
       " 'back': 61,\n",
       " 'vocal': 766,\n",
       " 'critic': 175,\n",
       " 'say': 623,\n",
       " 'could': 163,\n",
       " 'favour': 244,\n",
       " 'larg': 408,\n",
       " 'small': 657,\n",
       " 'firm': 265,\n",
       " 'impact': 349,\n",
       " 'open': 517,\n",
       " 'sourc': 668,\n",
       " 'softwar': 659,\n",
       " 'innov': 366,\n",
       " 'support': 699,\n",
       " 'would': 794,\n",
       " 'let': 421,\n",
       " 'protect': 571,\n",
       " 'intend': 369,\n",
       " 'offer': 511,\n",
       " 'use': 755,\n",
       " 'achiev': 8,\n",
       " 'effect': 215,\n",
       " 'word': 792,\n",
       " 'draft': 205,\n",
       " 'suffer': 695,\n",
       " 'setback': 640,\n",
       " 'poland': 551,\n",
       " 'one': 516,\n",
       " 'largest': 410,\n",
       " 'member': 459,\n",
       " 'state': 683,\n",
       " 'reject': 600,\n",
       " 'adopt': 17,\n",
       " 'twice': 743,\n",
       " 'two': 744,\n",
       " 'month': 482,\n",
       " 'intens': 370,\n",
       " 'lobbi': 429,\n",
       " 'issu': 379,\n",
       " 'start': 682,\n",
       " 'gain': 288,\n",
       " 'momentum': 477,\n",
       " 'nation': 494,\n",
       " 'put': 578,\n",
       " 'immens': 347,\n",
       " 'pressur': 562,\n",
       " 'meet': 457,\n",
       " 'vote': 769,\n",
       " 'abstain': 3,\n",
       " 'oppon': 518,\n",
       " 'welcom': 779,\n",
       " 'decis': 189,\n",
       " 'first': 266,\n",
       " 'read': 591,\n",
       " 'give': 295,\n",
       " 'chanc': 117,\n",
       " 'fuller': 284,\n",
       " 'debat': 186,\n",
       " 'implic': 351,\n",
       " 'us': 754,\n",
       " 'program': 567,\n",
       " 'internet': 373,\n",
       " 'busi': 100,\n",
       " 'method': 465,\n",
       " 'permit': 540,\n",
       " 'mean': 454,\n",
       " 'amazon': 35,\n",
       " 'com': 133,\n",
       " 'hold': 329,\n",
       " 'click': 126,\n",
       " 'shop': 646,\n",
       " 'servic': 638,\n",
       " 'exampl': 231,\n",
       " 'concern': 150,\n",
       " 'lead': 416,\n",
       " 'similar': 652,\n",
       " 'model': 476,\n",
       " 'happen': 315,\n",
       " 'europ': 226,\n",
       " 'fear': 247,\n",
       " 'hurt': 342,\n",
       " 'develop': 198,\n",
       " 'financi': 260,\n",
       " 'might': 468,\n",
       " 'larger': 409,\n",
       " 'compani': 142,\n",
       " 'fight': 255,\n",
       " 'action': 11,\n",
       " 'court': 168,\n",
       " 'current': 180,\n",
       " 'ineffici': 362,\n",
       " 'serv': 637,\n",
       " 'even': 228,\n",
       " 'play': 548,\n",
       " 'field': 254,\n",
       " 'without': 788,\n",
       " 'bring': 88,\n",
       " 'line': 425,\n",
       " 'tsunami': 739,\n",
       " 'debt': 187,\n",
       " 'deal': 185,\n",
       " 'announc': 40,\n",
       " 'chancellor': 118,\n",
       " 'gordon': 301,\n",
       " 'brown': 96,\n",
       " 'hope': 333,\n",
       " 'suspend': 703,\n",
       " 'interest': 371,\n",
       " 'repay': 603,\n",
       " 'hit': 328,\n",
       " 'later': 413,\n",
       " 'friday': 282,\n",
       " 'agreement': 26,\n",
       " 'group': 311,\n",
       " 'wealthi': 776,\n",
       " 'save': 622,\n",
       " 'affect': 19,\n",
       " 'countri': 166,\n",
       " 'bn': 78,\n",
       " 'pound': 557,\n",
       " 'year': 796,\n",
       " 'thought': 726,\n",
       " 'hammer': 314,\n",
       " 'thursday': 729,\n",
       " 'night': 505,\n",
       " 'japan': 383,\n",
       " 'biggest': 76,\n",
       " 'creditor': 173,\n",
       " 'final': 258,\n",
       " 'sign': 650,\n",
       " 'mr': 488,\n",
       " 'idea': 343,\n",
       " 'earlier': 212,\n",
       " 'week': 778,\n",
       " 'minist': 472,\n",
       " 'also': 33,\n",
       " 'believ': 70,\n",
       " 'agre': 25,\n",
       " 'instruct': 368,\n",
       " 'world': 793,\n",
       " 'bank': 63,\n",
       " 'intern': 372,\n",
       " 'monetari': 479,\n",
       " 'fund': 286,\n",
       " 'complet': 148,\n",
       " 'analysi': 38,\n",
       " 'reconstruct': 598,\n",
       " 'problem': 566,\n",
       " 'face': 238,\n",
       " 'disast': 201,\n",
       " 'lock': 430,\n",
       " 'talk': 711,\n",
       " 'financ': 259,\n",
       " 'britain': 89,\n",
       " 'chair': 113,\n",
       " 'germani': 294,\n",
       " 'freez': 281,\n",
       " 'canada': 106,\n",
       " 'begun': 68,\n",
       " 'moratorium': 483,\n",
       " 'expect': 236,\n",
       " 'come': 134,\n",
       " 'foreign': 269,\n",
       " 'secretari': 630,\n",
       " 'jack': 380,\n",
       " 'straw': 689,\n",
       " 'number': 508,\n",
       " 'briton': 91,\n",
       " 'dead': 184,\n",
       " 'miss': 474,\n",
       " 'reach': 590,\n",
       " 'soni': 665,\n",
       " 'psp': 574,\n",
       " 'tip': 732,\n",
       " 'must': 492,\n",
       " 'playstat': 549,\n",
       " 'portabl': 554,\n",
       " 'top': 734,\n",
       " 'gadget': 287,\n",
       " 'accord': 5,\n",
       " 'round': 613,\n",
       " 'ultim': 747,\n",
       " 'gizmo': 296,\n",
       " 'compil': 146,\n",
       " 'stuff': 692,\n",
       " 'magazin': 436,\n",
       " 'beat': 67,\n",
       " 'ipod': 377,\n",
       " 'second': 628,\n",
       " 'place': 546,\n",
       " 'ten': 720,\n",
       " 'essenti': 221,\n",
       " 'list': 426,\n",
       " 'predict': 559,\n",
       " 'lover': 434,\n",
       " 'like': 424,\n",
       " 'covet': 171,\n",
       " 'own': 526,\n",
       " 'set': 639,\n",
       " 'cheaper': 122,\n",
       " 'last': 412,\n",
       " 'due': 209,\n",
       " 'fall': 240,\n",
       " 'manufactur': 444,\n",
       " 'cost': 162,\n",
       " 'make': 441,\n",
       " 'afford': 20,\n",
       " 'domin': 203,\n",
       " 'includ': 355,\n",
       " 'sharp': 645,\n",
       " 'mobil': 475,\n",
       " 'phone': 543,\n",
       " 'pentax': 537,\n",
       " 'optio': 520,\n",
       " 'sv': 705,\n",
       " 'digit': 199,\n",
       " 'camera': 103,\n",
       " 'samsung': 619,\n",
       " 'yepp': 797,\n",
       " 'yh': 798,\n",
       " 'video': 762,\n",
       " 'jukebox': 389,\n",
       " 'show': 647,\n",
       " 'sexier': 642,\n",
       " 'indispens': 360,\n",
       " 'ever': 230,\n",
       " 'we': 775,\n",
       " 'got': 302,\n",
       " 'point': 550,\n",
       " 'can': 105,\n",
       " 'live': 427,\n",
       " 'certain': 111,\n",
       " 'technolog': 716,\n",
       " 'adam': 14,\n",
       " 'vaughan': 758,\n",
       " 'editor': 213,\n",
       " 'prolifer': 568,\n",
       " 'home': 332,\n",
       " 'inexor': 363,\n",
       " 'alter': 34,\n",
       " 'role': 611,\n",
       " 'high': 326,\n",
       " 'street': 690,\n",
       " 'think': 724,\n",
       " 'take': 709,\n",
       " 'pay': 535,\n",
       " 'entir': 219,\n",
       " 'film': 257,\n",
       " 'photo': 545,\n",
       " 'legitim': 419,\n",
       " 'download': 204,\n",
       " 'travel': 736,\n",
       " 'mile': 470,\n",
       " 'record': 599,\n",
       " 'song': 664,\n",
       " 'minut': 473,\n",
       " 'ask': 52,\n",
       " 'next': 502,\n",
       " 'see': 632,\n",
       " 'captur': 107,\n",
       " 'imagin': 346,\n",
       " 'xbox': 795,\n",
       " 'definit': 192,\n",
       " 'tv': 741,\n",
       " 'mp': 486,\n",
       " 'among': 37,\n",
       " 'have': 318,\n",
       " 'spring': 677,\n",
       " 'launch': 414,\n",
       " 'uk': 746,\n",
       " 'eager': 210,\n",
       " 'await': 60,\n",
       " 'game': 289,\n",
       " 'fan': 241,\n",
       " 'bnp': 79,\n",
       " 'leader': 417,\n",
       " 'nick': 504,\n",
       " 'griffin': 309,\n",
       " 'arrest': 51,\n",
       " 'british': 90,\n",
       " 'parti': 532,\n",
       " 'part': 531,\n",
       " 'polic': 552,\n",
       " 'inquiri': 367,\n",
       " 'follow': 267,\n",
       " 'screen': 625,\n",
       " 'bbc': 66,\n",
       " 'documentari': 202,\n",
       " 'spokesman': 672,\n",
       " 'tuesday': 740,\n",
       " 'morn': 484,\n",
       " 'suspicion': 704,\n",
       " 'incit': 354,\n",
       " 'commit': 137,\n",
       " 'racial': 586,\n",
       " 'hatr': 317,\n",
       " 'west': 782,\n",
       " 'yorkshir': 799,\n",
       " 'confirm': 152,\n",
       " 'old': 514,\n",
       " 'man': 442,\n",
       " 'outsid': 523,\n",
       " 'area': 47,\n",
       " 'found': 274,\n",
       " 'chairman': 114,\n",
       " 'john': 385,\n",
       " 'tyndal': 745,\n",
       " 'sunday': 698,\n",
       " 'charg': 119,\n",
       " 'juli': 390,\n",
       " 'secret': 629,\n",
       " 'agent': 22,\n",
       " 'featur': 248,\n",
       " 'covert': 170,\n",
       " 'footag': 268,\n",
       " 'activist': 12,\n",
       " 'twelfth': 742,\n",
       " 'nine': 506,\n",
       " 'men': 460,\n",
       " 'anoth': 42,\n",
       " 'leicest': 420,\n",
       " 'freed': 280,\n",
       " 'bail': 62,\n",
       " 'seven': 641,\n",
       " 'held': 322,\n",
       " 'various': 757,\n",
       " 'connect': 153,\n",
       " 'suspect': 702,\n",
       " 'aggrav': 23,\n",
       " 'public': 575,\n",
       " 'offenc': 510,\n",
       " 'conspiraci': 155,\n",
       " 'crimin': 174,\n",
       " 'damag': 182,\n",
       " 'possess': 556,\n",
       " 'firearm': 264,\n",
       " 'keighley': 393,\n",
       " 'septemb': 636,\n",
       " 'detain': 196,\n",
       " 'monday': 478,\n",
       " 'spokesperson': 673,\n",
       " 'brighton': 87,\n",
       " 'speech': 669,\n",
       " 'made': 435,\n",
       " 'burnley': 99,\n",
       " 'lancashir': 405,\n",
       " 'releas': 602,\n",
       " 'secur': 631,\n",
       " 'warn': 772,\n",
       " 'fbi': 246,\n",
       " 'virus': 765,\n",
       " 'feder': 250,\n",
       " 'bureau': 98,\n",
       " 'investig': 375,\n",
       " 'spread': 676,\n",
       " 'via': 760,\n",
       " 'mail': 438,\n",
       " 'purport': 577,\n",
       " 'gov': 303,\n",
       " 'address': 16,\n",
       " 'tell': 719,\n",
       " 'recipi': 597,\n",
       " 'access': 4,\n",
       " 'illeg': 345,\n",
       " 'websit': 777,\n",
       " 'messag': 464,\n",
       " 'monitor': 481,\n",
       " 'fraud': 278,\n",
       " 'complaint': 147,\n",
       " 'center': 110,\n",
       " 'attach': 55,\n",
       " 'contain': 156,\n",
       " 'answer': 43,\n",
       " 'question': 580,\n",
       " 'rather': 589,\n",
       " 'questionnair': 581,\n",
       " 'infect': 364,\n",
       " 'agenc': 21,\n",
       " 'clear': 125,\n",
       " 'user': 756,\n",
       " 'never': 499,\n",
       " 'unsolicit': 752,\n",
       " 'peopl': 538,\n",
       " 'know': 401,\n",
       " 'solicit': 660,\n",
       " 'engag': 218,\n",
       " 'practic': 558,\n",
       " 'send': 634,\n",
       " 'manner': 443,\n",
       " 'statement': 684,\n",
       " 'phoney': 544,\n",
       " 'shut': 648,\n",
       " 'account': 6,\n",
       " 'communic': 141,\n",
       " 'breach': 85,\n",
       " 'spokeswoman': 674,\n",
       " 'incid': 353,\n",
       " 'appear': 45,\n",
       " 'unrel': 751,\n",
       " 'sullivan': 696,\n",
       " 'run': 616,\n",
       " 'sonia': 666,\n",
       " 'indic': 359,\n",
       " 'particip': 533,\n",
       " 'cross': 177,\n",
       " 'championship': 116,\n",
       " 'st': 679,\n",
       " 'etienn': 224,\n",
       " 'athlet': 54,\n",
       " 'ireland': 378,\n",
       " 'hint': 327,\n",
       " 'cobh': 129,\n",
       " 'runner': 617,\n",
       " 'may': 451,\n",
       " 'offici': 513,\n",
       " 'event': 229,\n",
       " 'franc': 276,\n",
       " 'march': 446,\n",
       " 'provinci': 573,\n",
       " 'team': 715,\n",
       " 'select': 633,\n",
       " 'saturday': 621,\n",
       " 'santri': 620,\n",
       " 'present': 561,\n",
       " 'prepar': 560,\n",
       " 'london': 431,\n",
       " 'marathon': 445,\n",
       " 'april': 46,\n",
       " 'currentili': 181,\n",
       " 'train': 735,\n",
       " 'australia': 58,\n",
       " 'boost': 81,\n",
       " 'bronz': 95,\n",
       " 'three': 727,\n",
       " 'agio': 24,\n",
       " 'jolen': 388,\n",
       " 'byrn': 101,\n",
       " 'maria': 447,\n",
       " 'mccambridg': 452,\n",
       " 'fionnualla': 263,\n",
       " 'britton': 92,\n",
       " 'automat': 59,\n",
       " 'form': 270,\n",
       " 'long': 432,\n",
       " 'cours': 167,\n",
       " 'bupa': 97,\n",
       " 'great': 307,\n",
       " 'dublin': 207,\n",
       " 'merritt': 463,\n",
       " 'close': 128,\n",
       " 'indoor': 361,\n",
       " 'mark': 448,\n",
       " 'teenag': 717,\n",
       " 'lashawn': 411,\n",
       " 'ran': 588,\n",
       " 'third': 725,\n",
       " 'fastest': 243,\n",
       " 'time': 731,\n",
       " 'fayettevill': 245,\n",
       " 'invit': 376,\n",
       " 'junior': 391,\n",
       " 'champion': 115,\n",
       " 'clock': 127,\n",
       " 'finish': 261,\n",
       " 'well': 780,\n",
       " 'fellow': 252,\n",
       " 'american': 36,\n",
       " 'bershawn': 72,\n",
       " 'jackson': 381,\n",
       " 'arkansa': 49,\n",
       " 'michael': 467,\n",
       " 'johnson': 386,\n",
       " 'gone': 299,\n",
       " 'quicker': 582,\n",
       " 'sec': 627,\n",
       " 'kenyan': 396,\n",
       " 'bernard': 71,\n",
       " 'lagat': 404,\n",
       " 'quickest': 583,\n",
       " 'nate': 493,\n",
       " 'brannen': 84,\n",
       " 'almost': 31,\n",
       " 'olymp': 515,\n",
       " 'silver': 651,\n",
       " 'medallist': 456,\n",
       " 'inferior': 365,\n",
       " 'moroccan': 485,\n",
       " 'hicham': 325,\n",
       " 'el': 217,\n",
       " 'guerrouj': 312,\n",
       " 'former': 271,\n",
       " 'holder': 330,\n",
       " 'eamonn': 211,\n",
       " 'coghlan': 130,\n",
       " 'break': 86,\n",
       " 'maintain': 439,\n",
       " 'pace': 527,\n",
       " 'continu': 158,\n",
       " 'excel': 232,\n",
       " 'win': 786,\n",
       " 'tight': 730,\n",
       " 'cragg': 172,\n",
       " 'recent': 595,\n",
       " 'defeat': 190,\n",
       " 'kenenisa': 395,\n",
       " 'bekel': 69,\n",
       " 'boston': 82,\n",
       " 'ethiopian': 223,\n",
       " 'colleagu': 131,\n",
       " 'marko': 449,\n",
       " 'geneti': 293,\n",
       " 'victori': 761,\n",
       " 'carrol': 109,\n",
       " 'join': 387,\n",
       " 'solid': 661,\n",
       " 'gold': 298,\n",
       " 'jamaica': 382,\n",
       " 'women': 789,\n",
       " 'equal': 220,\n",
       " 'person': 541,\n",
       " 'best': 73,\n",
       " 'hurdl': 341,\n",
       " 'improv': 352,\n",
       " 'season': 626,\n",
       " 'mps': 487,\n",
       " 'quiz': 584,\n",
       " 'aid': 27,\n",
       " 'royal': 614,\n",
       " 'incom': 356,\n",
       " 'senior': 635,\n",
       " 'bodi': 80,\n",
       " 'generat': 292,\n",
       " 'privat': 564,\n",
       " 'queen': 579,\n",
       " 'princ': 563,\n",
       " 'wale': 770,\n",
       " 'duchi': 208,\n",
       " 'lancast': 406,\n",
       " 'cornwal': 160,\n",
       " 'common': 139,\n",
       " 'report': 604,\n",
       " 'charl': 120,\n",
       " 'spend': 670,\n",
       " 'camilla': 104,\n",
       " 'parker': 529,\n",
       " 'bowl': 83,\n",
       " 'correspond': 161,\n",
       " 'peter': 542,\n",
       " 'hunt': 340,\n",
       " 'respons': 606,\n",
       " 'money': 480,\n",
       " 'spent': 671,\n",
       " 'unabl': 748,\n",
       " 'provid': 572,\n",
       " 'annual': 41,\n",
       " 'acr': 9,\n",
       " 'estat': 222,\n",
       " 'across': 10,\n",
       " 'counti': 165,\n",
       " 'residenti': 605,\n",
       " 'properti': 569,\n",
       " 'offic': 512,\n",
       " 'stock': 687,\n",
       " 'share': 644,\n",
       " 'king': 398,\n",
       " 'edward': 214,\n",
       " 'iii': 344,\n",
       " 'success': 694,\n",
       " 'heir': 321,\n",
       " 'throne': 728,\n",
       " 'cover': 169,\n",
       " 'life': 423,\n",
       " 'neither': 496,\n",
       " 'william': 785,\n",
       " 'harri': 316,\n",
       " 'receiv': 594,\n",
       " 'taxpay': 714,\n",
       " 'civil': 124,\n",
       " 'howev': 338,\n",
       " 'depart': 194,\n",
       " 'grant': 306,\n",
       " 'voluntarili': 768,\n",
       " 'paid': 528,\n",
       " 'tax': 713,\n",
       " 'sinc': 653,\n",
       " 'hotspot': 336,\n",
       " 'free': 279,\n",
       " 'net': 497,\n",
       " 'call': 102,\n",
       " 'wireless': 787,\n",
       " 'soon': 667,\n",
       " 'abl': 2,\n",
       " 'surf': 701,\n",
       " 'broadreach': 93,\n",
       " 'telephoni': 718,\n",
       " 'skype': 656,\n",
       " 'roll': 612,\n",
       " 'around': 50,\n",
       " 'need': 495,\n",
       " 'wi': 784,\n",
       " 'fi': 253,\n",
       " 'allow': 30,\n",
       " 'pc': 536,\n",
       " 'system': 708,\n",
       " 'landlin': 407,\n",
       " 'fee': 251,\n",
       " 'popular': 553,\n",
       " 'million': 471,\n",
       " 'dub': 206,\n",
       " 'far': 242,\n",
       " 'attract': 56,\n",
       " 'plan': 547,\n",
       " 'add': 15,\n",
       " 'forthcom': 272,\n",
       " 'conferenc': 151,\n",
       " 'voic': 767,\n",
       " 'connectotel': 154,\n",
       " 'unveil': 753,\n",
       " 'expand': 235,\n",
       " 'sms': 658,\n",
       " 'function': 285,\n",
       " 'text': 722,\n",
       " 'network': 498,\n",
       " 'virgin': 764,\n",
       " 'megastor': 458,\n",
       " 'travelodg': 737,\n",
       " 'chain': 112,\n",
       " 'hotel': 335,\n",
       " 'major': 440,\n",
       " 'rail': 587,\n",
       " 'termin': 721,\n",
       " 'known': 402,\n",
       " 'delight': 193,\n",
       " 'comment': 135,\n",
       " 'chief': 123,\n",
       " 'execut': 234,\n",
       " 'magnus': 437,\n",
       " 'mcewen': 453,\n",
       " 'sight': 649,\n",
       " 'determin': 197,\n",
       " 'februari': 249,\n",
       " 'norwich': 507,\n",
       " 'grand': 305,\n",
       " 'prix': 565,\n",
       " 'birmingham': 77,\n",
       " 'chase': 121,\n",
       " 'compatriot': 143,\n",
       " 'mentor': 461,\n",
       " 'hail': 313,\n",
       " 'gebrselassi': 291,\n",
       " 'still': 686,\n",
       " 'hungri': 339,\n",
       " 'much': 490,\n",
       " 'sport': 675,\n",
       " 'aim': 28,\n",
       " 'target': 712,\n",
       " 'stand': 680,\n",
       " 'eight': 216,\n",
       " 'stranger': 688,\n",
       " 'overhaul': 525,\n",
       " 'arena': 48,\n",
       " 'broke': 94,\n",
       " 'debut': 188,\n",
       " 'mulugeta': 491,\n",
       " 'wondimu': 790,\n",
       " 'abiyot': 1,\n",
       " 'abat': 0,\n",
       " 'race': 585,\n",
       " 'alreadi': 32,\n",
       " 'crop': 176,\n",
       " 'talent': 710,\n",
       " 'kelli': 394,\n",
       " 'holm': 331,\n",
       " 'swedish': 706,\n",
       " 'heptathlon': 324,\n",
       " 'carolina': 108,\n",
       " 'kluft': 400,\n",
       " 'contest': 157,\n",
       " 'relay': 601,\n",
       " 'jason': 384,\n",
       " 'garden': 290,\n",
       " 'lewi': 422,\n",
       " 'franci': 277,\n",
       " 'go': 297,\n",
       " 'head': 320,\n",
       " 'true': 738,\n",
       " 'immigr': 348,\n",
       " 'data': 183,\n",
       " 'independ': 357,\n",
       " 'barbara': 64,\n",
       " 'roch': 610,\n",
       " 'organis': 522,\n",
       " 'publish': 576,\n",
       " 'figur': 256,\n",
       " 'counter': 164,\n",
       " 'migrat': 469,\n",
       " 'watch': 773,\n",
       " 'describ': 195,\n",
       " 'anti': 44,\n",
       " 'pose': 555,\n",
       " 'accur': 7,\n",
       " 'sir': 654,\n",
       " 'andrew': 39,\n",
       " 'green': 308,\n",
       " 'statist': 685,\n",
       " 'oppos': 519,\n",
       " 'scale': 624,\n",
       " 'ground': 310,\n",
       " 'overcrowd': 524,\n",
       " 'cultur': 179,\n",
       " 'household': 337,\n",
       " 'india': 358,\n",
       " 'four': 275,\n",
       " 'ms': 489,\n",
       " 'labour': 403,\n",
       " 'hornsey': 334,\n",
       " 'wood': 791,\n",
       " 'someth': 662,\n",
       " 'expert': 237,\n",
       " 'view': 763,\n",
       " 'went': 781,\n",
       " 'actual': 13,\n",
       " 'look': 433,\n",
       " 'way': 774,\n",
       " 'allay': 29,\n",
       " 'sometim': 663,\n",
       " 'whip': 783,\n",
       " 'collin': 132,\n",
       " 'compet': 144,\n",
       " 'commonwealth': 140,\n",
       " 'kim': 397,\n",
       " 'kitt': 399,\n",
       " 'nevi': 500,\n",
       " 'star': 681,\n",
       " 'sydney': 707,\n",
       " 'mauric': 450,\n",
       " 'athen': 53,\n",
       " 'obikwelu': 509,\n",
       " 'forward': 273,\n",
       " 'strong': 691,\n",
       " 'recept': 596,\n",
       " 'crowd': 178,\n",
       " 'nia': 503,\n",
       " 'medal': 455,\n",
       " 'realli': 592,\n",
       " 'excit': 233,\n",
       " 'return': 608,\n",
       " 'venu': 759,\n",
       " 'he': 319,\n",
       " 'good': 300,\n",
       " 'shape': 643,\n",
       " 'underestim': 749,\n",
       " 'competit': 145,\n",
       " 'sure': 700,\n",
       " 'they': 723,\n",
       " 'll': 428,\n",
       " 'front': 283,\n",
       " 'sprinter': 678,\n",
       " 'metr': 466,\n",
       " 'sixth': 655,\n",
       " 'better': 74,\n",
       " 'result': 607,\n",
       " 'finland': 262,\n",
       " 'summer': 697,\n",
       " 'big': 75,\n",
       " 'defend': 191,\n",
       " 'titl': 733,\n",
       " 'helsinki': 323,\n",
       " 'august': 57,\n",
       " 'want': 771,\n",
       " 'perform': 539}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:54:31.988574Z",
     "start_time": "2019-07-09T18:54:31.980196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 1088\n",
      "Percentage of cells containing 0: 88.67%\n"
     ]
    }
   ],
   "source": [
    "# Edit code before running it\n",
    "\n",
    "non_zero_cols = np.sum(df.values>0)\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / np.ma.count(df.values))\n",
    "print('Percentage of cells containing 0: {:.2%}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Create the tf-idf for the **whole** corpus of 12 articles\n",
    "- What are _on average_ the most important words in the whole corpus?\n",
    "- Add a column named \"Target\" to the dataset\n",
    "- Target will be set to 1 or 0 if the article is \"Politics\" or \"Not Politics\"\n",
    "- Do some exploratory analysis of the dataset\n",
    " - what are the average most important words for the \"Politics\" articles?\n",
    " - What are the average most important words for the \"Not Politics\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets talk classification\n",
    "- How would you split into train and test? what would be the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
